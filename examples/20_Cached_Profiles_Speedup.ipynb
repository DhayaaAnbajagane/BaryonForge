{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e1107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys, os; sys.path.insert(0, '../')\n",
    "import BaryonForge as bfg\n",
    "import pyccl as ccl\n",
    "\n",
    "#Load cosmology object from CCL. Linear P(k) is needed since we use it for 2-halo term.\n",
    "#We don't use P(k) anywhere else in this model, so it's ok to use linear P(k) throughout\n",
    "cosmo = ccl.Cosmology(Omega_c = 0.26, Omega_b = 0.04, h = 0.7, sigma8 = 0.8, n_s = 0.96, matter_power_spectrum='linear')\n",
    "h     = cosmo.cosmo.params.h\n",
    "\n",
    "#Config params. Can change as you need. I store these as a dict and then unpack.\n",
    "bpar_S19 = dict(theta_ej = 4, theta_co = 0.1, M_c = 1e14/h, mu_beta = 0.4,\n",
    "                eta = 0.3, eta_delta = 0.3, tau = -1.5, tau_delta = 0, #Must use tau here since we go down to low mass\n",
    "                A = 0.09/2, M1 = 2.5e11/h, epsilon_h = 0.015, \n",
    "                a = 0.3, n = 2, epsilon = 4, p = 0.3, q = 0.707, gamma = 2, delta = 7)\n",
    "\n",
    "bpar_A20 = dict(alpha_g = 2, epsilon_h = 0.015, M1_0 = 2.2e11/h, \n",
    "                alpha_fsat = 1, M1_fsat = 1, delta_fsat = 1, gamma_fsat = 1, eps_fsat = 1,\n",
    "                M_c = 1.2e14/h, eta = 0.6, mu = 0.31, beta = 0.6, epsilon_hydro = np.sqrt(5),\n",
    "                M_inn = 3.3e13/h, M_r = 1e16, beta_r = 2, theta_inn = 0.1, theta_out = 3,\n",
    "                theta_rg = 0.3, sigma_rg = 0.1, a = 0.3, n = 2, p = 0.3, q = 0.707,\n",
    "                A_nt = 0.495, alpha_nt = 0.1,\n",
    "                mean_molecular_weight = 0.59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de4cae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some plotting configs\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('font', family='serif', size=22)\n",
    "plt.rcParams[\"axes.linewidth\"]  = 2.0\n",
    "plt.rcParams[\"xtick.major.size\"]  = 10\n",
    "plt.rcParams[\"xtick.minor.size\"]  = 5\n",
    "plt.rcParams[\"ytick.major.size\"]  = 10\n",
    "plt.rcParams[\"ytick.minor.size\"]  = 5\n",
    "plt.rcParams[\"xtick.direction\"]  = \"in\"\n",
    "plt.rcParams[\"ytick.direction\"]  = \"in\"\n",
    "plt.rcParams[\"legend.frameon\"] = 'False'\n",
    "plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007fd580",
   "metadata": {},
   "source": [
    "# Profile evaluations\n",
    "\n",
    "Let's show utility of caching at the profile-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fe14b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "a     = 1\n",
    "R     = np.geomspace(1e-3, 1e1, 100) #In reality we'd eval at many more radii\n",
    "M200c = np.geomspace(1e9, 1e16, 100) #This is largely representative of the masses used (in halo model calculations)\n",
    "\n",
    "#Define the profile as usual. The cache can be done by simply\n",
    "#passing a BFG profile into the CachedProfile class. This\n",
    "#class simply caches results from the `real`, `fourier`, and `projected`\n",
    "#functions of the class instances.\n",
    "DMB        = bfg.Profiles.Schneider19.DarkMatterBaryon(**bpar_S19)\n",
    "DMB_cached = bfg.utils.CachedProfile(DMB)\n",
    "\n",
    "#We do one eval here, this will cache the result.\n",
    "#This takes as long as the regular calc, which we profile below\n",
    "DMB_cached.fourier(cosmo, R, M200c, a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa5ca24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.05 s, sys: 141 ms, total: 2.19 s\n",
      "Wall time: 1.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#The regular calculation is a couple of seconds (on my old laptop)\n",
    "prof  = DMB.fourier(cosmo, R, M200c, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd74def4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 196 Î¼s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#The cached version is five orders of magnitude faster, since it's just\n",
    "#the read-out time.\n",
    "prof  = DMB_cached.fourier(cosmo, R, M200c, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0548a3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.12 s, sys: 31.2 ms, total: 2.16 s\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#But if we change the input mass limit ever so slightly, the cache key\n",
    "#is different and so the calculation is redone, leading to slower runtime.\n",
    "prof  = DMB_cached.fourier(cosmo, R, M200c[:98], a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c56b8acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#You can also confirm the cached version is identical to re-evaluating the whole thing\n",
    "print(np.allclose(DMB.real(cosmo, R, M200c, a), DMB_cached.real(cosmo, R, M200c, a)))\n",
    "print(np.allclose(DMB.fourier(cosmo, R, M200c, a), DMB_cached.fourier(cosmo, R, M200c, a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5770e9e4",
   "metadata": {},
   "source": [
    "# Multicomponent/wavelength observables\n",
    "\n",
    "The main benefit to cache-ing is when you do multi-component halomodel P(k) calculations. In this case, you are evaluating the fourier version of a profile everytime that component (e.g., Gas, Dark Matter, Stars, etc.) shows up in an auto or cross-correlation. Removing the repetition will lead to massive improvements.\n",
    "\n",
    "The demonstration below follows largerly from Notebook 14 on HaloModel P(k) but now using caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f0e7a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a    = 1 #Compute everything at z = 0\n",
    "k    = np.geomspace(1e-3, 20, 100) #Compute across a wide range in k [1/Mpc, comoving]\n",
    "rho  = ccl.rho_x(cosmo, a, 'matter', is_comoving = True)\n",
    "\n",
    "#We will use the built-in, CCL halo model calculation tools.\n",
    "HMC  = ccl.halos.halo_model.HMCalculator(mass_function = 'Tinker08', halo_bias = 'Tinker10', \n",
    "                                         mass_def = ccl.halos.massdef.MassDef200c, \n",
    "                                         log10M_min = 9, log10M_max = 16, nM = 100)\n",
    "\n",
    "\n",
    "fft_precision = dict(padding_lo_fftlog = 1e-8, padding_hi_fftlog = 1e8, n_per_decade = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc809a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "par = bpar_S19\n",
    "\n",
    "#Define the standard profiles, with various integration limits\n",
    "DMO = bfg.Profiles.Schneider19.DarkMatter(**bpar_S19, r_min_int = 1e-3, r_max_int = 1e2, r_steps = 500)\n",
    "GAS = bfg.Profiles.Schneider19.Gas(**bpar_S19, r_min_int = 1e-3, r_max_int = 1e2, r_steps = 500)\n",
    "STR = bfg.Profiles.Schneider19.Stars(**bpar_S19, r_min_int = 1e-6, r_max_int = 5, r_steps = 500)\n",
    "CLM = bfg.Profiles.Schneider19.CollisionlessMatter(**bpar_S19, max_iter = 2, reltol = 5e-2, r_steps = 500)\n",
    "DMB = bfg.Profiles.Schneider19.DarkMatterBaryon(GAS, STR, CLM, DMO, bfg.Profiles.misc.Zeros(), **bpar_S19)\n",
    "PRS = bfg.Profiles.Pressure(gas = GAS, darkmatterbaryon = DMB, **bpar_S19, r_min_int = 1e-4, r_max_int = 1e2, r_steps = 500)\n",
    "\n",
    "#A function that gives us the M(r --> infty) mass of a given halo. Needed for Halomodel.\n",
    "M_2_Mtot = bfg.Profiles.misc.Mdelta_to_Mtot(DMO, r_min = 1e-6, r_max = 1e2, N_int = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9de0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now make a version of all profiles where we use cached versions.\n",
    "DMO_cached = bfg.utils.CachedProfile(DMO)\n",
    "GAS_cached = bfg.utils.CachedProfile(GAS)\n",
    "STR_cached = bfg.utils.CachedProfile(STR)\n",
    "CLM_cached = bfg.utils.CachedProfile(CLM)\n",
    "DMB_cached = bfg.utils.CachedProfile(DMB)\n",
    "PRS_cached = bfg.utils.CachedProfile(PRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27e36cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upgrade precision of all profiles for fourier-space calculation\n",
    "for p in [DMO, GAS, STR, CLM, DMB, PRS]: p.update_precision_fftlog(**fft_precision)\n",
    "for p in [DMO_cached, GAS_cached, STR_cached, CLM_cached, DMB_cached, PRS_cached]: p.update_precision_fftlog(**fft_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ddd9b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to use an alternative HM calculator when using Schneider19 since Mtot is defined at R --> infinity.\n",
    "#See Notebook 14 for more details.\n",
    "HMC_flex = bfg.utils.FlexibleHMCalculator(mass_function = 'Tinker08', halo_bias = 'Tinker10', halo_m_to_mtot = M_2_Mtot,\n",
    "                                          mass_def = ccl.halos.massdef.MassDef200c, \n",
    "                                          log10M_min = 9, log10M_max = 16, nM = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48584112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/g/My Drive/OneDrive/Research/GitHub/BaryonForge/examples/../BaryonForge/Profiles/Schneider19.py:784: UserWarning: Decrease integral lower limit, r_min_int (1e-08) < minimum radius (1.0000000000000001e-11)\n",
      "  warnings.warn(f\"Decrease integral lower limit, r_min_int ({self.r_min_int}) < minimum radius ({np.min(r)})\", UserWarning)\n",
      "/mnt/g/My Drive/OneDrive/Research/GitHub/BaryonForge/examples/../BaryonForge/Profiles/Schneider19.py:786: UserWarning: Increase integral upper limit, r_max_int (100000.0) < maximum radius (2000000000.0)\n",
      "  warnings.warn(f\"Increase integral upper limit, r_max_int ({self.r_max_int}) < maximum radius ({np.max(r)})\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 s, sys: 93.8 ms, total: 17.6 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Now let's compute the auto/cross of different profiles.\n",
    "#This takes 10 sec on my laptop, and most of the time is spent\n",
    "#re-evaluating the profiles many times. And especially redoing the\n",
    "#fourier space calculations many times.\n",
    "\n",
    "Fiducial  = []\n",
    "prof_list = [GAS, STR, CLM, DMB, PRS]\n",
    "for p in range(len(prof_list)):\n",
    "    for q in range(p, len(prof_list)):\n",
    "        Pk = ccl.halos.pk_2pt.halomod_power_spectrum(cosmo, HMC_flex, k, a, \n",
    "                                                     prof_list[p], prof2 = prof_list[q], \n",
    "                                                     suppress_1h = lambda k : 1e-2)\n",
    "        \n",
    "        Fiducial.append(Pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61b6659e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.86 s, sys: 0 ns, total: 1.86 s\n",
      "Wall time: 1.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#If we cache it, we get a 10x speedup. Note that we didn't pre-cache everything\n",
    "#This 10x speed-up is simply from eliminating the brute-force recalculations of\n",
    "#the profiles.\n",
    "\n",
    "Cached  = []\n",
    "prof_list = [GAS_cached, STR_cached, CLM_cached, DMB_cached, PRS_cached]\n",
    "for p in range(len(prof_list)):\n",
    "    for q in range(p, len(prof_list)):\n",
    "        Pk = ccl.halos.pk_2pt.halomod_power_spectrum(cosmo, HMC_flex, k, a, \n",
    "                                                     prof_list[p], prof2 = prof_list[q], \n",
    "                                                     suppress_1h = lambda k : 1e-2)\n",
    "        Cached.append(Pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0598282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The Fiducial and Cached versions are identical\n",
    "np.allclose(Fiducial, Cached)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b232d41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 15.6 ms, total: 15.6 ms\n",
      "Wall time: 16 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#If I run it one more time, it is dramatically faster,  since I have everything in cache now\n",
    "#So now we have a 500x speedup instead. Though in practice, there shouldn't be much of a\n",
    "#reason to do this kind of re-evaluation.\n",
    "prof_list = [GAS_cached, STR_cached, CLM_cached, DMB_cached, PRS_cached]\n",
    "for p in range(len(prof_list)):\n",
    "    for q in range(p, len(prof_list)):\n",
    "        Pk = ccl.halos.pk_2pt.halomod_power_spectrum(cosmo, HMC_flex, k, a, \n",
    "                                                     prof_list[p], prof2 = prof_list[q], \n",
    "                                                     suppress_1h = lambda k : 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669fe857",
   "metadata": {},
   "source": [
    "**NOTE:** You could also use the `TabulatedProfile` class in BaryonForge. But for halo-model calculations, the `CachedProfile` approach will be exact, whereas the Tabulated approach will incur some uncertainties (unless the the nodes of the Table are exactly/closely lined up with the masses and redshifts used for the halomodel calculation)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyccl3",
   "language": "python",
   "name": "pyccl3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
